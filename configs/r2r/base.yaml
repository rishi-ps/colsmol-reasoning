retriever:
  model_name: "vidore/colSmol-256M"
  use_lora: true
  lora_rank: 32
  lora_alpha: 32
  enable_gradient_checkpointing: false

reasoning_llm: # Needed for TraceGenerator if used online, though we use offline traces mostly
  model_name: "Qwen/Qwen2.5-0.5B-Instruct"
  device: "cuda"
  max_new_tokens: 100
  temperature: 0.7

training:
  learning_rate: 5.0e-6 # Reduced to prevent NaN
  batch_size: 2       # Must be >=2 for in-batch negatives
  gradient_accumulation_steps: 8 # Effective batch size = 16
  num_epochs: 3
  warmup_steps: 100
  temperature: 0.1
  separator: " [SEP] "

output:
  checkpoint_dir: "checkpoints/r2r"
